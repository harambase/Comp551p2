Mean validation score: 0.6646633089179602
std: 0.008123315021906805
Parameters: {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.40053644159285917, 'clf__n_estimators': 190, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0010083260374073057, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}
accruracy = 0.6079394583112055

{'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.40053644159285917, 'clf__n_estimators': 190, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0010083260374073057, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}

{'mean_fit_time': array([101.25715699,   1.71152954,  21.63806458,  10.46258607,
       174.58111982,  13.98922582,   5.92492185,  65.61749544,
         1.63347969,  26.06107821,  15.93170948,   5.07394481,
        76.44031911,  19.0582859 ,   6.2345356 ,  63.19645505,
       119.04813919,  12.95648084,  96.20633764,   1.94230714,
         5.69915905,  83.67540569,   1.54063821,   2.07541718,
         9.0477078 ,  24.59730792,  97.95407596,  25.31664901,
         3.47049518,   5.14165421,   3.112502  ,  17.58637905,
        18.62274089,  20.06242137, 157.55425277,   5.19986343,
         7.01111059,   6.31816139,   8.81505899,  20.32892251,
        68.55238199,  52.04232545,   6.00019755,   6.58252215,
         7.92374334,  39.13649316,  22.77141337,   9.92316203,
         7.32752719,  18.80177932,   6.27413521,  53.71041632,
         3.40128589,  21.35245152, 110.45224314,   3.96447997,
         3.02587237,  21.74578233,  49.33264456,  50.84761767,
        30.57650356,   6.8840302 ,  94.59770555,  82.75373178,
       167.37362409,  15.00481405, 249.62900763,   5.15486407,
         8.18409872,   1.25108876,   6.52153697,  18.02271104,
        56.8943789 ,  19.32037158,  21.07932916,   2.0668282 ,
         1.23269949,   5.32157164,   1.11713099,   4.55366588,
        65.03704152,   3.7024169 ,  12.95545201,   5.35425754,
        61.30273643,  42.32940812,   4.77455392,   4.47595487,
        40.68086162, 197.73527093, 147.47810364, 293.86485572,
        26.69186893,  96.04505467,   6.47089   ,  11.10526252,
         5.5230979 ,  77.48737392,   7.52963109,  10.12789445,
         4.58598571, 113.02870755,   2.3200582 ,   2.99938426,
        68.49033337,   5.37635512, 111.35170856,   1.90543499,
       354.99083877,  26.0660151 , 164.83876386,   6.77559381,
         4.3739953 ,   1.19601703,  47.90063024,  79.46255941,
        11.67892056,   4.10971026,   4.53944139,   9.28559613,
        12.07601914,  30.14083333,   1.13861651, 203.71287036,
         8.304633  ,   3.97855778, 161.54830742,  32.39240766,
       333.49342237,  47.64282336,  20.86598868,  23.53496246,
         1.76741037,  51.71321268,  12.79016757,  22.460922  ,
        28.27617526, 117.57999616,   8.55308266,  10.51990476,
         8.50589542, 106.1392005 ,   3.46655912, 144.06786079,
       229.70408359,  15.84631653,  26.6533278 ,   3.46289144,
        73.06315813,   1.55648866,  17.57758932,   4.76847715,
         3.71662045,   5.27093606, 233.82880073,  23.25936961,
        25.87236261,  25.89060197,  11.75835533, 136.45465012,
       292.98722301,  68.87125607,   2.86543522,  78.4643146 ,
        19.26840959,  22.36216774,  10.23080468,  83.18377595,
        29.82267556, 110.47074814,  17.86218691,  11.57442017,
        30.7659327 ,   4.95502176,  13.12854781, 209.87148452,
         8.48623409,  24.23878098,  22.22469702,  44.96245127,
         9.97541299,   9.5173214 ,  10.35804496,   8.92067218,
         5.68617349,  13.9353126 ,   3.7937026 ,  13.88819122,
         1.08615746,  27.75872111,  60.21748261,  37.8555954 ,
         7.25791516,  92.25874267,  14.34135041,   1.92978096,
        13.48657532, 117.53833623,   5.57028003,   1.91532907]), 'std_fit_time': array([1.13671602e+00, 2.56645503e-01, 2.88302653e+00, 1.34057617e-01,
       6.15668340e+00, 1.46594798e-01, 7.15637761e-02, 9.37205805e+00,
       2.07388076e-01, 1.72820996e+00, 1.52932024e-01, 1.01819069e-01,
       5.93404462e+00, 2.04206270e-01, 3.40620405e-01, 9.59141366e-01,
       9.74444778e+00, 1.34459556e+00, 8.76856814e-01, 3.28699995e-02,
       1.09684845e-01, 9.73705472e-01, 2.92155618e-01, 4.69745435e-02,
       8.93950263e-02, 1.66227608e+00, 8.31547193e-01, 1.70006856e+00,
       6.12830371e-02, 3.83103302e-02, 3.94253653e-02, 1.62670663e-01,
       1.31268657e-01, 1.94810808e-01, 9.06682259e+00, 5.48135733e-02,
       1.04600016e-01, 6.35460536e-02, 4.60996742e-01, 4.38468249e-01,
       1.17031679e+00, 4.90030297e+00, 3.25311442e-01, 1.01158566e-01,
       1.09137111e-01, 1.47517022e+00, 1.36396901e+00, 1.20412749e+00,
       9.87483492e-02, 4.41797785e-01, 8.71886227e-01, 8.54506307e-01,
       1.89080221e-01, 2.89416500e-01, 6.89195471e+00, 7.11641605e-02,
       6.45196719e-02, 1.17608984e+00, 3.05609850e+00, 4.39373189e+00,
       1.91772934e+00, 2.56395250e-01, 1.22502786e+00, 8.36731711e+00,
       4.14145473e+00, 1.13663418e-01, 3.45037372e+00, 7.60230792e-02,
       3.67261790e-01, 1.26875392e-02, 7.99843204e-02, 3.98104356e-01,
       3.45941983e+00, 2.39044890e+00, 3.49005111e-01, 1.73127505e-02,
       1.43359388e-02, 6.23555926e-02, 1.80285216e-02, 7.15303956e-02,
       3.08638311e+00, 5.27480772e-01, 1.90951397e+00, 1.72541670e-01,
       2.20051479e+00, 7.25037156e+00, 6.83554708e-02, 9.04833650e-02,
       7.05070057e-01, 3.79031220e+00, 9.02068692e+00, 5.08468013e+00,
       2.90765976e-01, 1.39286840e+00, 2.46529577e-02, 1.59697689e+00,
       5.32527584e-02, 1.69430689e+00, 1.17641150e-01, 1.72698987e+00,
       3.06062546e-01, 1.06147420e+00, 3.19012309e-01, 2.20807485e-02,
       1.95546219e+00, 1.90265432e-01, 1.02845005e+00, 3.51810484e-02,
       1.40585838e+01, 2.88913667e-01, 1.11253989e+01, 1.28924812e-01,
       1.32149503e-01, 4.31135853e-02, 3.32978195e+00, 2.22598623e+00,
       1.77583796e-01, 1.59230704e-01, 2.38971714e-01, 1.37124996e-01,
       1.21816648e-01, 4.07144439e-01, 5.37652124e-03, 1.19580670e+00,
       6.96682452e-02, 4.66234504e-02, 1.10270635e+01, 7.01913288e-01,
       4.62468010e+00, 4.79527704e-01, 1.82528227e-01, 4.78940190e-01,
       4.11625519e-02, 1.12326818e+00, 4.96012040e-01, 2.45713491e-01,
       2.64854756e+00, 1.61706818e+00, 9.68753554e-02, 1.38051330e+00,
       2.43379601e-01, 3.63455211e+00, 2.48465426e-02, 8.28986216e+00,
       6.97203272e+00, 6.07161166e-01, 7.77880886e-01, 4.52386605e-01,
       4.39423550e-01, 2.19340088e-01, 3.01173140e+00, 2.07045242e-01,
       1.14272139e-01, 1.34415797e-01, 1.56966061e+00, 6.51500803e-01,
       2.08968316e+00, 1.20637368e+00, 4.87802338e-01, 2.62041581e+00,
       1.85573700e+01, 1.07830527e+01, 1.43974230e-01, 4.79993496e-01,
       3.81572299e+00, 3.60167093e-01, 8.77816067e-01, 1.78846595e+00,
       1.09183415e+00, 9.56341841e+00, 3.64905293e-01, 1.68302489e-01,
       8.21674595e-01, 1.82022443e-01, 3.60853620e-01, 1.25028070e+01,
       9.10383091e-02, 2.15929541e-01, 3.11811137e+00, 1.02814178e+00,
       1.79442324e+00, 1.14838441e-01, 1.47445833e+00, 3.50939521e-01,
       3.49984452e-01, 3.74535389e-01, 2.19128994e-01, 2.31191982e-01,
       2.20933252e-02, 2.05971103e+00, 5.00383567e+00, 7.99940948e-01,
       1.07782334e+00, 2.59517654e+00, 3.02972910e-01, 3.26396616e-02,
       5.40731933e-01, 2.09937139e+00, 1.79293559e-01, 4.03723567e-02]), 'mean_score_time': array([1.41821542, 0.        , 0.80173316, 0.40546618, 1.23309216,
       0.41849704, 0.64656591, 0.93364415, 0.        , 0.6297143 ,
       0.42444372, 0.52276025, 0.59889655, 0.80619321, 0.85369225,
       0.6657577 , 1.43004041, 0.85783539, 1.80883937, 0.        ,
       0.        , 1.35648136, 0.        , 0.        , 0.83866782,
       0.46485062, 0.83151689, 0.53788142, 0.49491782, 0.7987452 ,
       0.51259351, 0.5556437 , 0.51867738, 0.74081521, 0.8235086 ,
       0.34450498, 0.39257536, 0.78428125, 0.91920924, 0.44894905,
       0.64283013, 1.36203103, 0.53941145, 0.69864922, 0.52594218,
       1.2608552 , 0.76824279, 1.024789  , 0.55248919, 0.49369063,
       0.        , 1.1052928 , 0.57471948, 0.6168242 , 0.80345502,
       0.        , 0.52203965, 0.53066068, 1.48076563, 1.01517   ,
       0.49482336, 0.46885099, 0.6751029 , 0.91980996, 1.86186233,
       2.27553215, 1.73777022, 0.        , 0.46379566, 0.        ,
       0.78771176, 0.66352849, 1.33379583, 2.35524201, 0.61439447,
       0.41021619, 0.        , 0.30815191, 0.        , 0.46838121,
       1.12095733, 0.71131477, 1.57347941, 0.3095448 , 0.82312617,
       1.0879683 , 0.30966287, 0.71697421, 1.23743954, 1.73957701,
       1.03246322, 2.81496305, 3.08964534, 1.46744633, 1.08774762,
       1.4536983 , 0.76445937, 1.35513644, 0.        , 1.33300838,
       0.        , 1.34813876, 0.44281559, 0.55172725, 1.96709785,
       0.        , 2.0270781 , 0.        , 2.80124454, 0.67212939,
       1.00566707, 0.44972816, 0.        , 0.        , 1.11959372,
       0.83087635, 0.50826564, 0.63216133, 0.        , 0.39616189,
       0.44448605, 0.69580188, 0.        , 1.39488001, 0.90189142,
       0.66589646, 1.27427459, 0.93224101, 2.36155276, 1.12691579,
       2.70217791, 0.58565907, 0.35509286, 0.86725645, 0.44985642,
       0.77325282, 0.88616862, 1.16696544, 1.12908707, 1.29944491,
       1.3652822 , 1.02132049, 0.60871072, 0.95915747, 2.36335416,
       0.70749087, 1.02614841, 0.60543299, 1.72131615, 0.        ,
       0.55806084, 0.        , 0.56608973, 0.        , 2.28304982,
       0.64304595, 3.54684758, 0.73105297, 0.70894718, 1.38912587,
       2.26358395, 1.1124176 , 0.47790008, 1.74627762, 2.42408099,
       0.86427836, 1.67304454, 1.12524748, 1.08292837, 0.89102068,
       0.57422085, 1.51977844, 0.52410717, 0.        , 0.5959991 ,
       1.16254458, 0.53083687, 0.53760681, 0.6829051 , 1.17453365,
       1.20121155, 0.34522848, 0.42733879, 0.46427054, 0.61732297,
       0.53032627, 0.        , 0.45366216, 0.        , 0.90869055,
       1.14653301, 1.01295657, 0.42361341, 0.95858369, 1.816152  ,
       0.        , 1.73360844, 2.5348022 , 0.        , 0.        ]), 'std_score_time': array([0.11035122, 0.        , 0.19224114, 0.01993106, 0.06144244,
       0.01687753, 0.03468795, 0.20997134, 0.        , 0.10744652,
       0.01579561, 0.05273103, 0.06010216, 0.03938652, 0.06114327,
       0.05753712, 0.17854921, 0.14287855, 0.33865383, 0.        ,
       0.        , 0.29701963, 0.        , 0.        , 0.05824475,
       0.02542406, 0.03043251, 0.03866167, 0.01719026, 0.02444843,
       0.0352802 , 0.02905282, 0.01142207, 0.0438829 , 0.05089147,
       0.01705176, 0.01874133, 0.03562785, 0.07926534, 0.02414471,
       0.07614206, 0.2090383 , 0.08465405, 0.04536507, 0.0186457 ,
       0.17060176, 0.13241423, 0.07282841, 0.06877428, 0.0773957 ,
       0.        , 0.0325114 , 0.01793887, 0.03602122, 0.02503982,
       0.        , 0.01299422, 0.10938206, 0.08371032, 0.1911563 ,
       0.02156232, 0.03734153, 0.08743942, 0.15288815, 0.39523859,
       0.0626724 , 0.30050109, 0.        , 0.02904802, 0.        ,
       0.03554363, 0.02304179, 0.26068375, 0.23935114, 0.01153689,
       0.01988785, 0.        , 0.02102378, 0.        , 0.04416186,
       0.21223105, 0.07834884, 0.36650644, 0.01391565, 0.15707597,
       0.23383596, 0.01378624, 0.03170309, 0.16869491, 0.27506966,
       0.16521622, 0.36608326, 0.35541295, 0.22455516, 0.04138747,
       0.24760292, 0.04078909, 0.20642165, 0.        , 0.33450982,
       0.        , 0.19104262, 0.06429781, 0.0499659 , 0.24333515,
       0.        , 0.2465096 , 0.        , 0.52692425, 0.0253825 ,
       0.08900606, 0.02829512, 0.        , 0.        , 0.06724626,
       0.08535343, 0.04408506, 0.04932181, 0.        , 0.01294989,
       0.01865423, 0.03004117, 0.        , 0.06270308, 0.04016202,
       0.01838178, 0.04491137, 0.04712893, 0.11256261, 0.04681587,
       0.10543161, 0.04169284, 0.01792186, 0.07438989, 0.04165667,
       0.02727919, 0.17020397, 0.23076136, 0.04990772, 0.28910584,
       0.15103846, 0.20117892, 0.0322957 , 0.154663  , 0.44140823,
       0.03320499, 0.12793113, 0.10512778, 0.22309692, 0.        ,
       0.1332138 , 0.        , 0.02631226, 0.        , 0.30544425,
       0.03700059, 0.56445613, 0.15303128, 0.02206005, 0.09391275,
       0.34535584, 0.06041672, 0.02905644, 0.30477816, 0.62041955,
       0.12630752, 0.41349899, 0.13496008, 0.2234446 , 0.07774783,
       0.04171752, 0.0585805 , 0.02364499, 0.        , 0.06020958,
       0.11018899, 0.03054555, 0.02270186, 0.17215567, 0.23102039,
       0.29711795, 0.01866366, 0.04818661, 0.0761871 , 0.08176783,
       0.03541755, 0.        , 0.01972546, 0.        , 0.18153259,
       0.05043583, 0.18536109, 0.08279879, 0.18185659, 0.05396897,
       0.        , 0.12981374, 0.5496069 , 0.        , 0.        ]), 'param_clf__algorithm': masked_array(data=['SAMME.R', 'SAMME.R', 'SAMME', 'SAMME.R', 'SAMME',
                   'SAMME', 'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R',
                   'SAMME.R', 'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME', 'SAMME', 'SAMME', 'SAMME.R',
                   'SAMME.R', 'SAMME.R', 'SAMME.R', 'SAMME.R', 'SAMME',
                   'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME',
                   'SAMME', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME.R',
                   'SAMME.R', 'SAMME', 'SAMME', 'SAMME', 'SAMME',
                   'SAMME.R', 'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME',
                   'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME.R', 'SAMME',
                   'SAMME', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME',
                   'SAMME.R', 'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R', 'SAMME',
                   'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME', 'SAMME',
                   'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME',
                   'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME',
                   'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R',
                   'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME',
                   'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R', 'SAMME',
                   'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R',
                   'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME.R',
                   'SAMME', 'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME', 'SAMME', 'SAMME', 'SAMME.R', 'SAMME',
                   'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME', 'SAMME.R', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME.R',
                   'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R', 'SAMME',
                   'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME', 'SAMME.R',
                   'SAMME.R', 'SAMME.R', 'SAMME.R', 'SAMME', 'SAMME.R',
                   'SAMME', 'SAMME', 'SAMME.R', 'SAMME.R', 'SAMME.R',
                   'SAMME.R', 'SAMME.R', 'SAMME.R'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_clf__base_estimator': masked_array(data=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None, None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None, None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None, None, None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None, None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   None, None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   None, None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None, None, None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None, None, None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None, None, None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None, None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   None,
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),
                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0),
                   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0)],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_clf__learning_rate': masked_array(data=[0.21567356623662093, 0.4426660099852713,
                   0.4369333189444752, 0.9932548827560241,
                   0.9533140516464685, 0.18598032577791568,
                   0.7913390932363434, 0.04422497961444727,
                   0.7579457703660711, 0.07710485813243007,
                   0.4738699312699647, 0.6897015093511942,
                   0.40053644159285917, 0.5466281406634406,
                   0.42779314929855816, 0.9984978286092498,
                   0.8142429858761493, 0.672298748694058,
                   0.5036980047712907, 0.09171900827184265,
                   0.23264849849635383, 0.07616282149282139,
                   0.27717054279326037, 0.30780524492466466,
                   0.35531269357721285, 0.9199429172307574,
                   0.3637207305354221, 0.2242745838125364,
                   0.21171549629789965, 0.9462348619354519,
                   0.4487351115870303, 0.916860898084947,
                   0.006420114966225854, 0.1394456202044534,
                   0.891585607880811, 0.4073986165887564,
                   0.15352552911370665, 0.5755551401645524,
                   0.9456377821786084, 0.659183719553142,
                   0.24546659456857278, 0.8698296289843264,
                   0.8517209609169634, 0.7205720892036513,
                   0.435787959044284, 0.6322609021823594,
                   0.79096333598921, 0.8233942145026744,
                   0.998397498611613, 0.7105975062611672,
                   0.9907629059929901, 0.82504744184486,
                   0.5744029844747237, 0.3974941599736702,
                   0.4677955544673872, 0.857170789533342,
                   0.9223231896469481, 0.0036414162838663833,
                   0.5520859903476202, 0.5936810209075328,
                   0.46275194437383904, 0.4031535639984035,
                   0.8266040940137035, 0.8957469774861074,
                   0.6041582345288277, 0.25435036834585556,
                   0.6626810921825169, 0.9030907844359197,
                   0.9022955155768604, 0.10577144547884176,
                   0.7799694013941356, 0.6493471157282311,
                   0.9009862331346044, 0.7397654238059699,
                   0.10496508454891129, 0.922955497279054,
                   0.8439373393075497, 0.24955785857209334,
                   0.3089106652832133, 0.23209206202921984,
                   0.6344788923196643, 0.4138206649627878,
                   0.2825303549964743, 0.971268906448796,
                   0.3044972453247966, 0.4956792232004166,
                   0.9915683858144471, 0.2945947987305745,
                   0.534398176371609, 0.2817835439707166,
                   0.7346154543210162, 0.728285194920634,
                   0.8432183870368942, 0.4907065851545108,
                   0.18771412607900317, 0.37238321596134727,
                   0.31651171123661825, 0.9591279055739624,
                   0.3609254655377272, 0.3291586741154182,
                   0.599883556429752, 0.5649262498528607,
                   0.9697508729570744, 0.008879563974460325,
                   0.917917362118127, 0.34828860710843,
                   0.6567100388770409, 0.33973148339242243,
                   0.9125197614641163, 0.32298764749813547,
                   0.6690070530688441, 0.011394510144386416,
                   0.5381851546305386, 0.8912092135707883,
                   0.6560998482004501, 0.9088249197478936,
                   0.2866575562970719, 0.38905155152274395,
                   0.9702223737811172, 0.19612560124602818,
                   0.004021210730897007, 0.010162884208830048,
                   0.9111616691055442, 0.22985176475125824,
                   0.3140028376248546, 0.818186101913455,
                   0.02738088781460357, 0.5126150839165732,
                   0.9375550756861655, 0.5862142384923615,
                   0.9371653973415063, 0.8262251775155807,
                   0.2998184666211512, 0.8271483210956343,
                   0.6650455040683423, 0.13262251099707145,
                   0.36405139242218465, 0.7522935555863304,
                   0.5625379070877576, 0.35272875909408297,
                   0.8343035213023698, 0.7810312965134912,
                   0.24268572225938478, 0.5359956769753176,
                   0.37482520288107046, 0.42525878512575954,
                   0.2004728541274574, 0.7935103683450433,
                   0.7307086443669016, 0.019106760264440026,
                   0.6615939800309736, 0.2698908863945225,
                   0.7229791650398212, 0.707083012473063,
                   0.2729290673889522, 0.31155445881005384,
                   0.2245112918135197, 0.4046632775650707,
                   0.9844718104486225, 0.7728649961296632,
                   0.5486195694357616, 0.013658063347293359,
                   0.8621975952498913, 0.591889546493937,
                   0.7765652660703344, 0.5876753338285926,
                   0.8297348139436076, 0.16645784776454686,
                   0.5370353263949288, 0.8928806507965322,
                   0.9335245974476243, 0.4638930093406016,
                   0.7220519174788482, 0.7376837648423874,
                   0.1242733295720232, 0.05287496251962809,
                   0.9466777382181656, 0.737976458417958,
                   0.004327060368255475, 0.10988921812616537,
                   0.049500467801142034, 0.49357157499063753,
                   0.14167695034764538, 0.4416996457118071,
                   0.14013316954655364, 0.7026083283970899,
                   0.4261945215197632, 0.9973614942712333,
                   0.3686574865425416, 0.16832742220801322,
                   0.01621370464812988, 0.30927615067908976,
                   0.39318893592466697, 0.2548877068279338,
                   0.33129196489724233, 0.6883645382879343,
                   0.41505149146512477, 0.35863867052408893,
                   0.3860722260433279, 0.39490202571115884],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_clf__n_estimators': masked_array(data=[395, 57, 179, 112, 373, 144, 77, 353, 101, 261, 165,
                   60, 190, 98, 57, 172, 362, 79, 325, 253, 95, 176, 168,
                   322, 34, 71, 226, 62, 213, 186, 91, 287, 207, 354, 329,
                   50, 62, 41, 311, 237, 108, 84, 22, 179, 62, 185, 27,
                   268, 58, 45, 53, 340, 84, 287, 334, 390, 119, 233, 258,
                   46, 367, 57, 171, 198, 339, 393, 385, 35, 61, 272, 51,
                   128, 272, 389, 305, 39, 188, 88, 201, 11, 56, 86, 156,
                   12, 145, 286, 66, 150, 210, 373, 254, 334, 296, 296,
                   197, 365, 234, 363, 41, 102, 10, 119, 42, 43, 370, 201,
                   340, 149, 378, 342, 359, 44, 242, 203, 88, 149, 171,
                   212, 374, 198, 194, 327, 182, 307, 173, 146, 321, 158,
                   315, 268, 314, 42, 21, 58, 134, 367, 173, 244, 43, 134,
                   328, 213, 87, 332, 324, 169, 27, 56, 235, 218, 263,
                   259, 167, 305, 378, 62, 347, 85, 54, 158, 286, 391, 77,
                   354, 356, 36, 396, 290, 116, 279, 280, 229, 84, 303,
                   163, 398, 58, 265, 361, 268, 64, 162, 156, 47, 98, 196,
                   398, 148, 16, 171, 185, 130, 60, 330, 174, 236, 172,
                   326, 161, 236],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_vect__max_df': masked_array(data=[0.7666666666666666, 0.6777777777777778, 0.5, 0.9,
                   0.7222222222222222, 0.8555555555555556,
                   0.6333333333333333, 0.8111111111111111,
                   0.8111111111111111, 0.7222222222222222,
                   0.8111111111111111, 0.9, 0.6333333333333333, 0.5,
                   0.7222222222222222, 0.8111111111111111,
                   0.6333333333333333, 0.9, 0.5, 0.5888888888888889,
                   0.8555555555555556, 0.5444444444444444,
                   0.8111111111111111, 0.7666666666666666,
                   0.8555555555555556, 0.5, 0.7666666666666666,
                   0.7222222222222222, 0.6777777777777778,
                   0.6777777777777778, 0.6777777777777778,
                   0.8111111111111111, 0.6333333333333333, 0.5, 0.5,
                   0.7666666666666666, 0.9, 0.8111111111111111,
                   0.6333333333333333, 0.6777777777777778,
                   0.8111111111111111, 0.7666666666666666,
                   0.7666666666666666, 0.8555555555555556,
                   0.8111111111111111, 0.9, 0.7666666666666666,
                   0.6777777777777778, 0.8111111111111111,
                   0.7666666666666666, 0.6777777777777778,
                   0.7222222222222222, 0.9, 0.7222222222222222, 0.5, 0.9,
                   0.5444444444444444, 0.8111111111111111,
                   0.6333333333333333, 0.8111111111111111,
                   0.6333333333333333, 0.7222222222222222,
                   0.7222222222222222, 0.5, 0.5888888888888889,
                   0.7222222222222222, 0.6777777777777778,
                   0.8555555555555556, 0.5888888888888889,
                   0.5888888888888889, 0.8555555555555556, 0.9, 0.5, 0.5,
                   0.9, 0.6777777777777778, 0.5444444444444444,
                   0.8111111111111111, 0.5888888888888889,
                   0.5888888888888889, 0.6777777777777778,
                   0.7666666666666666, 0.5888888888888889,
                   0.6333333333333333, 0.5444444444444444,
                   0.5444444444444444, 0.8555555555555556,
                   0.6333333333333333, 0.7666666666666666,
                   0.7222222222222222, 0.5888888888888889,
                   0.8111111111111111, 0.9, 0.5, 0.5888888888888889,
                   0.8111111111111111, 0.7666666666666666, 0.9,
                   0.7222222222222222, 0.5444444444444444,
                   0.8111111111111111, 0.7222222222222222,
                   0.6333333333333333, 0.8111111111111111, 0.9,
                   0.5888888888888889, 0.6777777777777778, 0.9,
                   0.5888888888888889, 0.8555555555555556,
                   0.7666666666666666, 0.5, 0.8111111111111111,
                   0.7222222222222222, 0.5888888888888889,
                   0.5444444444444444, 0.6777777777777778,
                   0.5888888888888889, 0.5888888888888889,
                   0.7666666666666666, 0.7666666666666666,
                   0.6777777777777778, 0.5888888888888889,
                   0.7666666666666666, 0.9, 0.5, 0.8555555555555556, 0.9,
                   0.5888888888888889, 0.8111111111111111,
                   0.5444444444444444, 0.5, 0.5888888888888889,
                   0.8555555555555556, 0.5, 0.5888888888888889,
                   0.5888888888888889, 0.9, 0.5, 0.5, 0.5444444444444444,
                   0.9, 0.7222222222222222, 0.7222222222222222, 0.9,
                   0.5888888888888889, 0.6333333333333333,
                   0.5888888888888889, 0.9, 0.7222222222222222,
                   0.5888888888888889, 0.7666666666666666,
                   0.6333333333333333, 0.6777777777777778,
                   0.6777777777777778, 0.5444444444444444,
                   0.6777777777777778, 0.6333333333333333, 0.5,
                   0.6777777777777778, 0.5, 0.9, 0.9, 0.7666666666666666,
                   0.6333333333333333, 0.7666666666666666,
                   0.6333333333333333, 0.5444444444444444,
                   0.6333333333333333, 0.9, 0.5888888888888889,
                   0.8555555555555556, 0.7222222222222222,
                   0.8111111111111111, 0.7222222222222222,
                   0.5444444444444444, 0.8555555555555556, 0.5,
                   0.5444444444444444, 0.6777777777777778,
                   0.5888888888888889, 0.6333333333333333,
                   0.8111111111111111, 0.8555555555555556, 0.9,
                   0.5888888888888889, 0.5, 0.8111111111111111, 0.5,
                   0.8111111111111111, 0.8111111111111111,
                   0.7666666666666666, 0.5, 0.5444444444444444, 0.5,
                   0.5888888888888889, 0.8111111111111111,
                   0.8111111111111111, 0.7666666666666666,
                   0.7222222222222222],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_vect__min_df': masked_array(data=[0.0015262103992892823, 0.0021586087603694838,
                   0.0016726995453788783, 0.007638859692677426,
                   0.001116454588732132, 0.004094646139573492,
                   0.0020356417450788176, 0.008298140318282276,
                   0.00263689023011183, 0.006169170378834181,
                   0.0011248635067955066, 0.0036585219375663415,
                   0.0010083260374073057, 0.001345144640413683,
                   0.0045062828298335226, 0.004574850031316612,
                   0.004438959539038705, 0.0018814170417083803,
                   0.0020300863602703218, 0.001410605171147304,
                   0.004050072196642136, 0.008555405170956114,
                   0.009035706115321264, 0.0027376860523113627,
                   0.007909141107152308, 0.008475662544249155,
                   0.0019583505018003658, 0.006597621685646764,
                   0.00575350289498268, 0.0015134910161156872,
                   0.0010596796614658424, 0.0027278780549262506,
                   0.0018510771527199686, 0.00704415414205899,
                   0.007528372269643027, 0.007903709757297634,
                   0.00312580083425388, 0.0025813730248314707,
                   0.002933628790586446, 0.002049904090588691,
                   0.0010535756141033907, 0.0017188581618862574,
                   0.006304944160105962, 0.006467638735434267,
                   0.0019491441836357224, 0.004622811877421459,
                   0.0011161202743032793, 0.0012938870770806616,
                   0.005655908830720016, 0.007151516944752779,
                   0.0026228425224258866, 0.0017882770962939696,
                   0.0014520402841209565, 0.001285347858998455,
                   0.004991222225859311, 0.009994936768739403,
                   0.006641359005746756, 0.003262891170572837,
                   0.0066678737594565145, 0.0017651487685366293,
                   0.0037986848761507376, 0.004019282249830937,
                   0.003919866847056014, 0.0017175909876034397,
                   0.008323109694758682, 0.0028715772351815836,
                   0.009690457707291952, 0.003164740799720874,
                   0.008992046618811044, 0.0018127995011667408,
                   0.005264555804676928, 0.008069495993795089,
                   0.002386892075878668, 0.005352246872010255,
                   0.0020403432739761816, 0.00488110712492821,
                   0.0031492941589118437, 0.007313297943242402,
                   0.0014608941704417643, 0.004444392662820201,
                   0.0014395696016416524, 0.005160529423187458,
                   0.0019915679672280672, 0.0024732777595361413,
                   0.0020287976726291014, 0.005962041249302547,
                   0.0028918661783814323, 0.0010106485017763475,
                   0.0071123060439978476, 0.0012061202759597047,
                   0.0024212585949125597, 0.0028445942415894275,
                   0.0013744141243317918, 0.0013388136066928484,
                   0.008617834489303547, 0.0036272842321092786,
                   0.004081044959892256, 0.002423590261448468,
                   0.002095567447322373, 0.007450489021492924,
                   0.0033356962031816546, 0.0017176387084472675,
                   0.003917034315798271, 0.004482944320711166,
                   0.005699029514236835, 0.0054928483660166135,
                   0.0014936166788546553, 0.002974373694209135,
                   0.002055220059624311, 0.005880681428125542,
                   0.0011010090959686436, 0.0013480903805572278,
                   0.002859269114267082, 0.0010876636455478606,
                   0.0016085597930047206, 0.001020253937150718,
                   0.007186473780778882, 0.009459515439012519,
                   0.0031373403657744318, 0.00886344601150082,
                   0.0024290231640855834, 0.0013616417975171287,
                   0.0065208397349863, 0.008538343562584629,
                   0.0014509289216151644, 0.005894782985607634,
                   0.0011680761374594894, 0.001031885215137773,
                   0.0010337291735758101, 0.0019019807167232402,
                   0.0012170982382820974, 0.0013881264715300706,
                   0.004406983823594092, 0.0044549976181945,
                   0.0014637148210952023, 0.00756750273620254,
                   0.0021822916900510947, 0.004280886366587665,
                   0.00805996656015951, 0.0018291945621635433,
                   0.004169972953001661, 0.003216901534626496,
                   0.007174002612696362, 0.0011135093466358161,
                   0.0029126570488414126, 0.002429661554787628,
                   0.003051808495502888, 0.0013945761459689962,
                   0.007080035833606496, 0.006184854018596128,
                   0.007319670369146938, 0.003906634970602572,
                   0.00727401049520024, 0.006933167660580464,
                   0.0036899243214601227, 0.0065003490292412985,
                   0.00300621474389794, 0.006122425757262543,
                   0.006656355902758419, 0.0031526916494514124,
                   0.001146427993627307, 0.007312499312829163,
                   0.003795805727871679, 0.0031545636298511387,
                   0.003413942476489048, 0.009890553898711305,
                   0.0014775897174176776, 0.0031081308450625943,
                   0.003927857100890553, 0.0023768028139773494,
                   0.0010769646738310178, 0.004774643474435638,
                   0.004482582166227314, 0.001119925174903347,
                   0.0017690196922354245, 0.0019478080235610653,
                   0.0010457032536463008, 0.0020895686604271908,
                   0.003563378304803905, 0.007451234380510314,
                   0.00111387320664766, 0.0037338045151924905,
                   0.0019796684400242787, 0.006893917145616804,
                   0.009213583201802157, 0.0033353895818652667,
                   0.001347364262403738, 0.00169824418446211,
                   0.004203433438894644, 0.0035353115881987533,
                   0.003234857893040514, 0.002155588152351481,
                   0.0032303923834529607, 0.0036937600397485863,
                   0.001064725480370095, 0.0019078100957155768,
                   0.0011479366470707986, 0.0056687455127229945,
                   0.008116421845556715, 0.00117712279744805],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_vect__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 1), (1, 2), (1, 1), (1, 2),
                   (1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1), (1, 2),
                   (1, 2), (1, 2), (1, 2), (1, 2), (1, 1), (1, 1), (1, 2),
                   (1, 2), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2), (1, 2),
                   (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1),
                   (1, 1), (1, 1), (1, 2), (1, 2), (1, 1), (1, 1), (1, 2),
                   (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2),
                   (1, 1), (1, 2), (1, 2), (1, 1), (1, 2), (1, 2), (1, 2),
                   (1, 1), (1, 1), (1, 1), (1, 2), (1, 1), (1, 2), (1, 1),
                   (1, 1), (1, 2), (1, 1), (1, 2), (1, 2), (1, 1), (1, 1),
                   (1, 2), (1, 1), (1, 1), (1, 2), (1, 2), (1, 1), (1, 1),
                   (1, 1), (1, 1), (1, 2), (1, 2), (1, 1), (1, 2), (1, 1),
                   (1, 1), (1, 2), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1),
                   (1, 2), (1, 2), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),
                   (1, 2), (1, 2), (1, 2), (1, 2), (1, 1), (1, 1), (1, 2),
                   (1, 2), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1), (1, 2),
                   (1, 2), (1, 1), (1, 2), (1, 2), (1, 2), (1, 1), (1, 2),
                   (1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 1),
                   (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 1),
                   (1, 2), (1, 1), (1, 2), (1, 2), (1, 1), (1, 2), (1, 2),
                   (1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1), (1, 2),
                   (1, 1), (1, 2), (1, 1), (1, 1), (1, 2), (1, 1), (1, 2),
                   (1, 2), (1, 1), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2),
                   (1, 1), (1, 1), (1, 2), (1, 2), (1, 2), (1, 1), (1, 1),
                   (1, 2), (1, 2), (1, 1), (1, 2), (1, 2), (1, 2), (1, 2),
                   (1, 1), (1, 2), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1),
                   (1, 1), (1, 1), (1, 2), (1, 2), (1, 2), (1, 1), (1, 1),
                   (1, 2), (1, 2), (1, 2), (1, 1), (1, 1), (1, 2), (1, 1),
                   (1, 2), (1, 2), (1, 2), (1, 1)],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_vect__stop_words': masked_array(data=['english', 'english', 'english', None, 'english', None,
                   'english', 'english', None, None, None, 'english',
                   'english', None, None, 'english', 'english', 'english',
                   None, 'english', 'english', None, 'english', None,
                   'english', 'english', 'english', 'english', 'english',
                   'english', 'english', 'english', None, 'english', None,
                   None, None, None, 'english', None, None, None,
                   'english', 'english', 'english', 'english', 'english',
                   'english', 'english', None, None, None, None,
                   'english', 'english', 'english', 'english', None, None,
                   None, None, 'english', None, 'english', None,
                   'english', None, None, 'english', 'english', None,
                   None, 'english', None, 'english', None, None,
                   'english', 'english', 'english', None, 'english', None,
                   'english', None, None, 'english', 'english', None,
                   'english', None, None, None, None, 'english', None,
                   None, 'english', None, None, 'english', None,
                   'english', None, 'english', None, None, 'english',
                   None, 'english', 'english', 'english', 'english',
                   'english', None, 'english', 'english', None, 'english',
                   'english', 'english', None, None, None, 'english',
                   'english', 'english', None, None, None, None,
                   'english', None, None, None, 'english', None, None,
                   None, 'english', None, None, 'english', 'english',
                   None, 'english', None, None, None, 'english',
                   'english', None, None, None, None, None, None,
                   'english', None, None, None, 'english', None,
                   'english', None, None, 'english', 'english', 'english',
                   'english', 'english', None, 'english', None, 'english',
                   None, 'english', None, 'english', 'english', None,
                   'english', 'english', 'english', 'english', 'english',
                   'english', None, 'english', None, 'english', 'english',
                   None, 'english', 'english', 'english', None, None,
                   'english', None],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_vect__token_pattern': masked_array(data=['\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{2,}',
                   '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{1,}',
                   '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{2,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{2,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{2,}',
                   '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{2,}',
                   '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}',
                   '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{2,}',
                   '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{2,}', '\\w{1,}',
                   '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{2,}',
                   '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{2,}',
                   '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{1,}', '\\w{1,}',
                   '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{1,}', '\\w{1,}',
                   '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{2,}',
                   '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}',
                   '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{1,}', '\\w{1,}',
                   '\\w{1,}', '\\w{1,}', '\\w{2,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{2,}', '\\w{2,}',
                   '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{1,}',
                   '\\w{2,}', '\\w{2,}', '\\w{1,}', '\\w{2,}', '\\w{2,}'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'params': [{'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.21567356623662093, 'clf__n_estimators': 395, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0015262103992892823, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.4426660099852713, 'clf__n_estimators': 57, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0021586087603694838, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.4369333189444752, 'clf__n_estimators': 179, 'vect__max_df': 0.5, 'vect__min_df': 0.0016726995453788783, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.9932548827560241, 'clf__n_estimators': 112, 'vect__max_df': 0.9, 'vect__min_df': 0.007638859692677426, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9533140516464685, 'clf__n_estimators': 373, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.001116454588732132, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.18598032577791568, 'clf__n_estimators': 144, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.004094646139573492, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.7913390932363434, 'clf__n_estimators': 77, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0020356417450788176, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.04422497961444727, 'clf__n_estimators': 353, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.008298140318282276, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.7579457703660711, 'clf__n_estimators': 101, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.00263689023011183, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.07710485813243007, 'clf__n_estimators': 261, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.006169170378834181, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.4738699312699647, 'clf__n_estimators': 165, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0011248635067955066, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.6897015093511942, 'clf__n_estimators': 60, 'vect__max_df': 0.9, 'vect__min_df': 0.0036585219375663415, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.40053644159285917, 'clf__n_estimators': 190, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0010083260374073057, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.5466281406634406, 'clf__n_estimators': 98, 'vect__max_df': 0.5, 'vect__min_df': 0.001345144640413683, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.42779314929855816, 'clf__n_estimators': 57, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.0045062828298335226, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9984978286092498, 'clf__n_estimators': 172, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.004574850031316612, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.8142429858761493, 'clf__n_estimators': 362, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.004438959539038705, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.672298748694058, 'clf__n_estimators': 79, 'vect__max_df': 0.9, 'vect__min_df': 0.0018814170417083803, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.5036980047712907, 'clf__n_estimators': 325, 'vect__max_df': 0.5, 'vect__min_df': 0.0020300863602703218, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.09171900827184265, 'clf__n_estimators': 253, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.001410605171147304, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.23264849849635383, 'clf__n_estimators': 95, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.004050072196642136, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.07616282149282139, 'clf__n_estimators': 176, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.008555405170956114, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.27717054279326037, 'clf__n_estimators': 168, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.009035706115321264, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.30780524492466466, 'clf__n_estimators': 322, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0027376860523113627, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.35531269357721285, 'clf__n_estimators': 34, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.007909141107152308, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9199429172307574, 'clf__n_estimators': 71, 'vect__max_df': 0.5, 'vect__min_df': 0.008475662544249155, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.3637207305354221, 'clf__n_estimators': 226, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0019583505018003658, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.2242745838125364, 'clf__n_estimators': 62, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.006597621685646764, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.21171549629789965, 'clf__n_estimators': 213, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.00575350289498268, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.9462348619354519, 'clf__n_estimators': 186, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0015134910161156872, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.4487351115870303, 'clf__n_estimators': 91, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0010596796614658424, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.916860898084947, 'clf__n_estimators': 287, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0027278780549262506, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.006420114966225854, 'clf__n_estimators': 207, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0018510771527199686, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.1394456202044534, 'clf__n_estimators': 354, 'vect__max_df': 0.5, 'vect__min_df': 0.00704415414205899, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.891585607880811, 'clf__n_estimators': 329, 'vect__max_df': 0.5, 'vect__min_df': 0.007528372269643027, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.4073986165887564, 'clf__n_estimators': 50, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.007903709757297634, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.15352552911370665, 'clf__n_estimators': 62, 'vect__max_df': 0.9, 'vect__min_df': 0.00312580083425388, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.5755551401645524, 'clf__n_estimators': 41, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0025813730248314707, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.9456377821786084, 'clf__n_estimators': 311, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.002933628790586446, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.659183719553142, 'clf__n_estimators': 237, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.002049904090588691, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.24546659456857278, 'clf__n_estimators': 108, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0010535756141033907, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.8698296289843264, 'clf__n_estimators': 84, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0017188581618862574, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.8517209609169634, 'clf__n_estimators': 22, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.006304944160105962, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.7205720892036513, 'clf__n_estimators': 179, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.006467638735434267, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.435787959044284, 'clf__n_estimators': 62, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0019491441836357224, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.6322609021823594, 'clf__n_estimators': 185, 'vect__max_df': 0.9, 'vect__min_df': 0.004622811877421459, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.79096333598921, 'clf__n_estimators': 27, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0011161202743032793, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.8233942145026744, 'clf__n_estimators': 268, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0012938870770806616, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.998397498611613, 'clf__n_estimators': 58, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.005655908830720016, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.7105975062611672, 'clf__n_estimators': 45, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.007151516944752779, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9907629059929901, 'clf__n_estimators': 53, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0026228425224258866, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.82504744184486, 'clf__n_estimators': 340, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.0017882770962939696, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.5744029844747237, 'clf__n_estimators': 84, 'vect__max_df': 0.9, 'vect__min_df': 0.0014520402841209565, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.3974941599736702, 'clf__n_estimators': 287, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.001285347858998455, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.4677955544673872, 'clf__n_estimators': 334, 'vect__max_df': 0.5, 'vect__min_df': 0.004991222225859311, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.857170789533342, 'clf__n_estimators': 390, 'vect__max_df': 0.9, 'vect__min_df': 0.009994936768739403, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.9223231896469481, 'clf__n_estimators': 119, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.006641359005746756, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.0036414162838663833, 'clf__n_estimators': 233, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.003262891170572837, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.5520859903476202, 'clf__n_estimators': 258, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0066678737594565145, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.5936810209075328, 'clf__n_estimators': 46, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0017651487685366293, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.46275194437383904, 'clf__n_estimators': 367, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0037986848761507376, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.4031535639984035, 'clf__n_estimators': 57, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.004019282249830937, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.8266040940137035, 'clf__n_estimators': 171, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.003919866847056014, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.8957469774861074, 'clf__n_estimators': 198, 'vect__max_df': 0.5, 'vect__min_df': 0.0017175909876034397, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.6041582345288277, 'clf__n_estimators': 339, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.008323109694758682, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.25435036834585556, 'clf__n_estimators': 393, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.0028715772351815836, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.6626810921825169, 'clf__n_estimators': 385, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.009690457707291952, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9030907844359197, 'clf__n_estimators': 35, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.003164740799720874, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.9022955155768604, 'clf__n_estimators': 61, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.008992046618811044, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.10577144547884176, 'clf__n_estimators': 272, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0018127995011667408, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.7799694013941356, 'clf__n_estimators': 51, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.005264555804676928, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.6493471157282311, 'clf__n_estimators': 128, 'vect__max_df': 0.9, 'vect__min_df': 0.008069495993795089, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.9009862331346044, 'clf__n_estimators': 272, 'vect__max_df': 0.5, 'vect__min_df': 0.002386892075878668, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.7397654238059699, 'clf__n_estimators': 389, 'vect__max_df': 0.5, 'vect__min_df': 0.005352246872010255, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.10496508454891129, 'clf__n_estimators': 305, 'vect__max_df': 0.9, 'vect__min_df': 0.0020403432739761816, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.922955497279054, 'clf__n_estimators': 39, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.00488110712492821, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.8439373393075497, 'clf__n_estimators': 188, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.0031492941589118437, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.24955785857209334, 'clf__n_estimators': 88, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.007313297943242402, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.3089106652832133, 'clf__n_estimators': 201, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0014608941704417643, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.23209206202921984, 'clf__n_estimators': 11, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.004444392662820201, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.6344788923196643, 'clf__n_estimators': 56, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0014395696016416524, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.4138206649627878, 'clf__n_estimators': 86, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.005160529423187458, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.2825303549964743, 'clf__n_estimators': 156, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0019915679672280672, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.971268906448796, 'clf__n_estimators': 12, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0024732777595361413, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.3044972453247966, 'clf__n_estimators': 145, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.0020287976726291014, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.4956792232004166, 'clf__n_estimators': 286, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.005962041249302547, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.9915683858144471, 'clf__n_estimators': 66, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.0028918661783814323, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.2945947987305745, 'clf__n_estimators': 150, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0010106485017763475, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.534398176371609, 'clf__n_estimators': 210, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0071123060439978476, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.2817835439707166, 'clf__n_estimators': 373, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.0012061202759597047, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.7346154543210162, 'clf__n_estimators': 254, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0024212585949125597, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.728285194920634, 'clf__n_estimators': 334, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0028445942415894275, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.8432183870368942, 'clf__n_estimators': 296, 'vect__max_df': 0.9, 'vect__min_df': 0.0013744141243317918, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.4907065851545108, 'clf__n_estimators': 296, 'vect__max_df': 0.5, 'vect__min_df': 0.0013388136066928484, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.18771412607900317, 'clf__n_estimators': 197, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.008617834489303547, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.37238321596134727, 'clf__n_estimators': 365, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0036272842321092786, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.31651171123661825, 'clf__n_estimators': 234, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.004081044959892256, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.9591279055739624, 'clf__n_estimators': 363, 'vect__max_df': 0.9, 'vect__min_df': 0.002423590261448468, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.3609254655377272, 'clf__n_estimators': 41, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.002095567447322373, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.3291586741154182, 'clf__n_estimators': 102, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.007450489021492924, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.599883556429752, 'clf__n_estimators': 10, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0033356962031816546, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.5649262498528607, 'clf__n_estimators': 119, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.0017176387084472675, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.9697508729570744, 'clf__n_estimators': 42, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.003917034315798271, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.008879563974460325, 'clf__n_estimators': 43, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.004482944320711166, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.917917362118127, 'clf__n_estimators': 370, 'vect__max_df': 0.9, 'vect__min_df': 0.005699029514236835, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.34828860710843, 'clf__n_estimators': 201, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0054928483660166135, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.6567100388770409, 'clf__n_estimators': 340, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0014936166788546553, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.33973148339242243, 'clf__n_estimators': 149, 'vect__max_df': 0.9, 'vect__min_df': 0.002974373694209135, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.9125197614641163, 'clf__n_estimators': 378, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.002055220059624311, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.32298764749813547, 'clf__n_estimators': 342, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.005880681428125542, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.6690070530688441, 'clf__n_estimators': 359, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0011010090959686436, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.011394510144386416, 'clf__n_estimators': 44, 'vect__max_df': 0.5, 'vect__min_df': 0.0013480903805572278, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.5381851546305386, 'clf__n_estimators': 242, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.002859269114267082, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.8912092135707883, 'clf__n_estimators': 203, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.0010876636455478606, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.6560998482004501, 'clf__n_estimators': 88, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0016085597930047206, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9088249197478936, 'clf__n_estimators': 149, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.001020253937150718, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.2866575562970719, 'clf__n_estimators': 171, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.007186473780778882, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.38905155152274395, 'clf__n_estimators': 212, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.009459515439012519, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9702223737811172, 'clf__n_estimators': 374, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0031373403657744318, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.19612560124602818, 'clf__n_estimators': 198, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.00886344601150082, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.004021210730897007, 'clf__n_estimators': 194, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0024290231640855834, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.010162884208830048, 'clf__n_estimators': 327, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0013616417975171287, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9111616691055442, 'clf__n_estimators': 182, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0065208397349863, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.22985176475125824, 'clf__n_estimators': 307, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.008538343562584629, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.3140028376248546, 'clf__n_estimators': 173, 'vect__max_df': 0.9, 'vect__min_df': 0.0014509289216151644, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.818186101913455, 'clf__n_estimators': 146, 'vect__max_df': 0.5, 'vect__min_df': 0.005894782985607634, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.02738088781460357, 'clf__n_estimators': 321, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.0011680761374594894, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.5126150839165732, 'clf__n_estimators': 158, 'vect__max_df': 0.9, 'vect__min_df': 0.001031885215137773, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.9375550756861655, 'clf__n_estimators': 315, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0010337291735758101, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.5862142384923615, 'clf__n_estimators': 268, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0019019807167232402, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.9371653973415063, 'clf__n_estimators': 314, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.0012170982382820974, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.8262251775155807, 'clf__n_estimators': 42, 'vect__max_df': 0.5, 'vect__min_df': 0.0013881264715300706, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.2998184666211512, 'clf__n_estimators': 21, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.004406983823594092, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.8271483210956343, 'clf__n_estimators': 58, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.0044549976181945, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.6650455040683423, 'clf__n_estimators': 134, 'vect__max_df': 0.5, 'vect__min_df': 0.0014637148210952023, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.13262251099707145, 'clf__n_estimators': 367, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.00756750273620254, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.36405139242218465, 'clf__n_estimators': 173, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0021822916900510947, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.7522935555863304, 'clf__n_estimators': 244, 'vect__max_df': 0.9, 'vect__min_df': 0.004280886366587665, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.5625379070877576, 'clf__n_estimators': 43, 'vect__max_df': 0.5, 'vect__min_df': 0.00805996656015951, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.35272875909408297, 'clf__n_estimators': 134, 'vect__max_df': 0.5, 'vect__min_df': 0.0018291945621635433, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.8343035213023698, 'clf__n_estimators': 328, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.004169972953001661, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.7810312965134912, 'clf__n_estimators': 213, 'vect__max_df': 0.9, 'vect__min_df': 0.003216901534626496, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.24268572225938478, 'clf__n_estimators': 87, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.007174002612696362, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.5359956769753176, 'clf__n_estimators': 332, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.0011135093466358161, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.37482520288107046, 'clf__n_estimators': 324, 'vect__max_df': 0.9, 'vect__min_df': 0.0029126570488414126, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.42525878512575954, 'clf__n_estimators': 169, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.002429661554787628, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.2004728541274574, 'clf__n_estimators': 27, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.003051808495502888, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.7935103683450433, 'clf__n_estimators': 56, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0013945761459689962, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.7307086443669016, 'clf__n_estimators': 235, 'vect__max_df': 0.9, 'vect__min_df': 0.007080035833606496, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.019106760264440026, 'clf__n_estimators': 218, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.006184854018596128, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.6615939800309736, 'clf__n_estimators': 263, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.007319670369146938, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.2698908863945225, 'clf__n_estimators': 259, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.003906634970602572, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.7229791650398212, 'clf__n_estimators': 167, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.00727401049520024, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.707083012473063, 'clf__n_estimators': 305, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.006933167660580464, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.2729290673889522, 'clf__n_estimators': 378, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0036899243214601227, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.31155445881005384, 'clf__n_estimators': 62, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.0065003490292412985, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.2245112918135197, 'clf__n_estimators': 347, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.00300621474389794, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.4046632775650707, 'clf__n_estimators': 85, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.006122425757262543, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.9844718104486225, 'clf__n_estimators': 54, 'vect__max_df': 0.5, 'vect__min_df': 0.006656355902758419, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.7728649961296632, 'clf__n_estimators': 158, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.0031526916494514124, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.5486195694357616, 'clf__n_estimators': 286, 'vect__max_df': 0.5, 'vect__min_df': 0.001146427993627307, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.013658063347293359, 'clf__n_estimators': 391, 'vect__max_df': 0.9, 'vect__min_df': 0.007312499312829163, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.8621975952498913, 'clf__n_estimators': 77, 'vect__max_df': 0.9, 'vect__min_df': 0.003795805727871679, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.591889546493937, 'clf__n_estimators': 354, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.0031545636298511387, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.7765652660703344, 'clf__n_estimators': 356, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.003413942476489048, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.5876753338285926, 'clf__n_estimators': 36, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.009890553898711305, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.8297348139436076, 'clf__n_estimators': 396, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0014775897174176776, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.16645784776454686, 'clf__n_estimators': 290, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.0031081308450625943, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.5370353263949288, 'clf__n_estimators': 116, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.003927857100890553, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.8928806507965322, 'clf__n_estimators': 279, 'vect__max_df': 0.9, 'vect__min_df': 0.0023768028139773494, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.9335245974476243, 'clf__n_estimators': 280, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0010769646738310178, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.4638930093406016, 'clf__n_estimators': 229, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.004774643474435638, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.7220519174788482, 'clf__n_estimators': 84, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.004482582166227314, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.7376837648423874, 'clf__n_estimators': 303, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.001119925174903347, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.1242733295720232, 'clf__n_estimators': 163, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.0017690196922354245, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.05287496251962809, 'clf__n_estimators': 398, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.0019478080235610653, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.9466777382181656, 'clf__n_estimators': 58, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.0010457032536463008, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.737976458417958, 'clf__n_estimators': 265, 'vect__max_df': 0.5, 'vect__min_df': 0.0020895686604271908, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.004327060368255475, 'clf__n_estimators': 361, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.003563378304803905, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.10988921812616537, 'clf__n_estimators': 268, 'vect__max_df': 0.6777777777777778, 'vect__min_df': 0.007451234380510314, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.049500467801142034, 'clf__n_estimators': 64, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.00111387320664766, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.49357157499063753, 'clf__n_estimators': 162, 'vect__max_df': 0.6333333333333333, 'vect__min_df': 0.0037338045151924905, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.14167695034764538, 'clf__n_estimators': 156, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0019796684400242787, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.4416996457118071, 'clf__n_estimators': 47, 'vect__max_df': 0.8555555555555556, 'vect__min_df': 0.006893917145616804, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.14013316954655364, 'clf__n_estimators': 98, 'vect__max_df': 0.9, 'vect__min_df': 0.009213583201802157, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.7026083283970899, 'clf__n_estimators': 196, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0033353895818652667, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.4261945215197632, 'clf__n_estimators': 398, 'vect__max_df': 0.5, 'vect__min_df': 0.001347364262403738, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.9973614942712333, 'clf__n_estimators': 148, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.00169824418446211, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.3686574865425416, 'clf__n_estimators': 16, 'vect__max_df': 0.5, 'vect__min_df': 0.004203433438894644, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': None, 'clf__learning_rate': 0.16832742220801322, 'clf__n_estimators': 171, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0035353115881987533, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.01621370464812988, 'clf__n_estimators': 185, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.003234857893040514, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.30927615067908976, 'clf__n_estimators': 130, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.002155588152351481, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': None, 'clf__learning_rate': 0.39318893592466697, 'clf__n_estimators': 60, 'vect__max_df': 0.5, 'vect__min_df': 0.0032303923834529607, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.2548877068279338, 'clf__n_estimators': 330, 'vect__max_df': 0.5444444444444444, 'vect__min_df': 0.0036937600397485863, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.33129196489724233, 'clf__n_estimators': 174, 'vect__max_df': 0.5, 'vect__min_df': 0.001064725480370095, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.6883645382879343, 'clf__n_estimators': 236, 'vect__max_df': 0.5888888888888889, 'vect__min_df': 0.0019078100957155768, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'clf__learning_rate': 0.41505149146512477, 'clf__n_estimators': 172, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0011479366470707986, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'clf__learning_rate': 0.35863867052408893, 'clf__n_estimators': 326, 'vect__max_df': 0.8111111111111111, 'vect__min_df': 0.0056687455127229945, 'vect__ngram_range': (1, 2), 'vect__stop_words': None, 'vect__token_pattern': '\\w{1,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.3860722260433279, 'clf__n_estimators': 161, 'vect__max_df': 0.7666666666666666, 'vect__min_df': 0.008116421845556715, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english', 'vect__token_pattern': '\\w{2,}'}, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0), 'clf__learning_rate': 0.39490202571115884, 'clf__n_estimators': 236, 'vect__max_df': 0.7222222222222222, 'vect__min_df': 0.00117712279744805, 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__token_pattern': '\\w{2,}'}], 'split0_test_score': array([0.54485197,        nan, 0.32744145, 0.43526293, 0.6190897 ,
       0.26734423, 0.19840919, 0.55722492,        nan, 0.42554132,
       0.31109147, 0.1723376 , 0.67034909, 0.47061423, 0.4264251 ,
       0.56738842, 0.42554132, 0.45824127, 0.55059655,        nan,
              nan, 0.46354397,        nan,        nan, 0.35483871,
       0.54043305, 0.64516129, 0.59036677, 0.5280601 , 0.56738842,
       0.51391958, 0.43526293, 0.2841361 , 0.41537782, 0.53778171,
       0.40256297, 0.38488732, 0.1166593 , 0.31948741, 0.3809103 ,
       0.62615996, 0.4922669 , 0.25408749, 0.39019001, 0.43614671,
       0.53336279, 0.20327   , 0.30269554, 0.31727795, 0.15510384,
              nan, 0.42686699, 0.49403447, 0.34776845, 0.60141405,
              nan, 0.51215201, 0.09191339, 0.51436147, 0.12770658,
       0.38002651, 0.4215643 , 0.58152894, 0.29120636, 0.36367654,
       0.54087494, 0.5077331 ,        nan, 0.48254529,        nan,
       0.20327   , 0.46973045, 0.58462218, 0.53645603, 0.26336721,
       0.47017234,        nan, 0.24834291,        nan, 0.14184711,
       0.18029165, 0.49182501, 0.30004419, 0.53733981, 0.34467521,
       0.37207247, 0.33274414, 0.51966416, 0.49138312, 0.56296951,
       0.59964649, 0.32213875, 0.30004419, 0.55501547, 0.47282369,
       0.4874061 , 0.4719399 , 0.59787892,        nan, 0.45912506,
              nan, 0.23552806, 0.16349978, 0.44277508, 0.57003977,
              nan, 0.57313301,        nan, 0.34202386, 0.34953601,
       0.64339373, 0.09191339,        nan,        nan, 0.49624392,
       0.6040654 , 0.2894388 , 0.42421564,        nan, 0.43305347,
       0.26734423, 0.30888202,        nan, 0.53778171, 0.40344675,
       0.52098984, 0.64074238, 0.32567388, 0.59080866, 0.42863456,
       0.56164384, 0.58329651, 0.25099426, 0.49315068, 0.46928856,
       0.41272647, 0.30048608, 0.39019001, 0.16703491, 0.51347768,
       0.56606275, 0.34732656, 0.38621299, 0.66018559, 0.45514803,
       0.45735749, 0.16040654, 0.21564295, 0.48254529,        nan,
       0.37118869,        nan, 0.27883341,        nan, 0.52452497,
       0.26336721, 0.49712771, 0.36588599, 0.42288997, 0.31285904,
       0.63764914, 0.27176315, 0.22624834, 0.57092355, 0.37516571,
       0.19399028, 0.60362351, 0.55899249, 0.51966416, 0.61246133,
       0.45382236, 0.48298719, 0.58064516,        nan, 0.46486964,
       0.62881131, 0.43261158, 0.39416703, 0.30357932, 0.4772426 ,
       0.10826337, 0.33230225, 0.45868316, 0.46486964, 0.40433053,
       0.38356164,        nan, 0.45558992,        nan, 0.45117101,
       0.54264251, 0.51436147, 0.26822802, 0.52982766, 0.52010605,
              nan, 0.50154662, 0.48254529,        nan,        nan]), 'split1_test_score': array([0.53247901,        nan, 0.30048608, 0.44498453, 0.63323023,
       0.28325232, 0.21652673, 0.53468847,        nan, 0.42819266,
       0.29695095, 0.20547945, 0.6495802 , 0.47370747, 0.40300486,
       0.56650464, 0.42023862, 0.45779938, 0.54485197,        nan,
              nan, 0.44100751,        nan,        nan, 0.36146708,
       0.5280601 , 0.64030049, 0.58506407, 0.49049934, 0.55766681,
       0.49801149, 0.42907645, 0.28634556, 0.41361025, 0.53733981,
       0.40167919, 0.39505082, 0.13919576, 0.31374282, 0.38532921,
       0.63588157, 0.47812638, 0.2182943 , 0.31197525, 0.42730888,
       0.52143173, 0.11489174, 0.38267786, 0.29827662, 0.13742819,
              nan, 0.42377375, 0.4772426 , 0.33627928, 0.58771542,
              nan, 0.49801149, 0.10958904, 0.50508175, 0.14494034,
       0.3804684 , 0.41802916, 0.56031816, 0.27883341, 0.40786567,
       0.52938577, 0.5178966 ,        nan, 0.45558992,        nan,
       0.19001326, 0.46000884, 0.57445868, 0.51745471, 0.26027397,
       0.45338047,        nan, 0.23287671,        nan, 0.13566063,
       0.14891737, 0.46531153, 0.3402563 , 0.53513036, 0.43437914,
       0.37295625, 0.29739284, 0.50154662, 0.48298719, 0.51126823,
       0.60804242, 0.33937251, 0.24701723, 0.55810871, 0.44807777,
       0.50817499, 0.45735749, 0.59080866,        nan, 0.4312859 ,
              nan, 0.28325232, 0.15201061, 0.46045073, 0.55103844,
              nan, 0.55987627,        nan, 0.40035351, 0.33451171,
       0.65223155, 0.08749448,        nan,        nan, 0.48298719,
       0.60450729, 0.27750773, 0.3857711 ,        nan, 0.43040212,
       0.30136986, 0.32258065,        nan, 0.53999116, 0.39284136,
       0.50463986, 0.64427751, 0.30888202, 0.58727353, 0.41051701,
       0.55280601, 0.5634114 , 0.2487848 , 0.49447636, 0.4772426 ,
       0.39902784, 0.29518338, 0.31330093, 0.16438356, 0.49977905,
       0.54927088, 0.31064958, 0.36632788, 0.64648696, 0.42730888,
       0.46266019, 0.12019443, 0.1674768 , 0.46663721,        nan,
       0.38488732,        nan, 0.22227132,        nan, 0.51480336,
       0.25143615, 0.47459125, 0.27220504, 0.42244808, 0.22889969,
       0.63985859, 0.26513478, 0.18868758, 0.56252762, 0.39372514,
       0.14803358, 0.5939019 , 0.51436147, 0.51082634, 0.61997349,
       0.45249669, 0.48652232, 0.57534247,        nan, 0.45603182,
       0.62395051, 0.41847106, 0.38886434, 0.29209015, 0.45028723,
       0.10119311, 0.30269554, 0.45470614, 0.43879806, 0.42333186,
       0.37251436,        nan, 0.47326558,        nan, 0.44851966,
       0.55766681, 0.5024304 , 0.24569156, 0.54794521, 0.51082634,
              nan, 0.4922669 , 0.47149801,        nan,        nan]), 'split2_test_score': array([0.53645603,        nan, 0.31109147, 0.44498453, 0.63367212,
       0.27750773, 0.23552806, 0.56562086,        nan, 0.43570482,
       0.30225365, 0.15201061, 0.67300044, 0.47812638, 0.43349536,
       0.5687141 , 0.4414494 , 0.46045073, 0.54131684,        nan,
              nan, 0.50022095,        nan,        nan, 0.36014141,
       0.52098984, 0.65444101, 0.59699514, 0.51568714, 0.5585506 ,
       0.53115334, 0.45603182, 0.26822802, 0.42554132, 0.55148034,
       0.40477243, 0.40344675, 0.12593902, 0.4012373 , 0.38621299,
       0.64825453, 0.50596553, 0.2129916 , 0.36014141, 0.44189129,
       0.53336279, 0.15687141, 0.33760495, 0.29164825, 0.13742819,
              nan, 0.42509943, 0.49845338, 0.35130358, 0.60848431,
              nan, 0.52319929, 0.08749448, 0.51612903, 0.14538224,
       0.3809103 , 0.42421564, 0.57224923, 0.27618206, 0.42554132,
       0.53601414, 0.52629253,        nan, 0.49005745,        nan,
       0.15775519, 0.48961555, 0.58152894, 0.53601414, 0.28148475,
       0.48166151,        nan, 0.24834291,        nan, 0.13477684,
       0.12638091, 0.49580203, 0.42686699, 0.55148034, 0.41979673,
       0.36500221, 0.32213875, 0.52673442, 0.50331418, 0.52585064,
       0.62262483, 0.40653999, 0.31020769, 0.55015466, 0.4922669 ,
       0.52187362, 0.44233319, 0.60008838,        nan, 0.46752099,
              nan, 0.17498895, 0.19752541, 0.42996023, 0.57269112,
              nan, 0.56164384,        nan, 0.2231551 , 0.35086169,
       0.67255855, 0.08749448,        nan,        nan, 0.50861688,
       0.61290323, 0.28899691, 0.46663721,        nan, 0.43437914,
       0.27750773, 0.32213875,        nan, 0.56031816, 0.42686699,
       0.52938577, 0.67786125, 0.32390632, 0.61157755, 0.44763588,
       0.55280601, 0.56606275, 0.24657534, 0.49712771, 0.48917366,
       0.42288997, 0.30534688, 0.41802916, 0.15687141, 0.51922227,
       0.56517897, 0.30048608, 0.39328325, 0.6752099 , 0.46928856,
       0.47901016, 0.22227132, 0.13477684, 0.50110473,        nan,
       0.38665488,        nan, 0.2942996 ,        nan, 0.47901016,
       0.29871852, 0.49801149, 0.33141847, 0.43570482, 0.223597  ,
       0.6447194 , 0.26159965, 0.24259832, 0.56783031, 0.33804684,
       0.1117985 , 0.59478568, 0.5837384 , 0.52231551, 0.6040654 ,
       0.45735749, 0.49580203, 0.59257623,        nan, 0.45205479,
       0.63720725, 0.43923995, 0.42244808, 0.26955369, 0.48784799,
       0.10340256, 0.32390632, 0.46973045, 0.48298719, 0.44277508,
       0.38135219,        nan, 0.48121962,        nan, 0.47547503,
       0.57931949, 0.52673442, 0.26646045, 0.55722492, 0.5280601 ,
              nan, 0.50640742, 0.49624392,        nan,        nan]), 'split3_test_score': array([0.54264251,        nan, 0.31374282, 0.47061423, 0.64118427,
       0.24745913, 0.17587274, 0.55413168,        nan, 0.44189129,
       0.29827662, 0.17454706, 0.6650464 , 0.47414936, 0.38709677,
       0.58638975, 0.35262925, 0.48077773, 0.55148034,        nan,
              nan, 0.4516129 ,        nan,        nan, 0.36942112,
       0.53601414, 0.66018559, 0.60273973, 0.52629253, 0.56783031,
       0.49977905, 0.46884666, 0.26071586, 0.42775077, 0.56517897,
       0.41714538, 0.4007954 , 0.08572691, 0.30313743, 0.38356164,
       0.65841803, 0.48254529, 0.223597  , 0.24790102, 0.44586832,
       0.53778171, 0.13389306, 0.4719399 , 0.31418471, 0.1931065 ,
              nan, 0.43040212, 0.48121962, 0.33406982, 0.60848431,
              nan, 0.52319929, 0.08970393, 0.51524525, 0.10914715,
       0.37516571, 0.44277508, 0.58815731, 0.37251436, 0.39991162,
       0.53999116, 0.53733981,        nan, 0.48342908,        nan,
       0.15687141, 0.47282369, 0.59346001, 0.53159523, 0.28325232,
       0.46884666,        nan, 0.23596995,        nan, 0.15333628,
       0.16040654, 0.48033584, 0.32213875, 0.56120194, 0.46000884,
       0.37914273, 0.31727795, 0.50110473, 0.49933716, 0.58329651,
       0.62218294, 0.25762262, 0.31816173, 0.55236412, 0.46973045,
       0.51215201, 0.48033584, 0.61025188,        nan, 0.43968184,
              nan, 0.26557667, 0.11931065, 0.45028723, 0.58152894,
              nan, 0.55678303,        nan, 0.36235086, 0.33627928,
       0.6752099 , 0.08970393,        nan,        nan, 0.47635882,
       0.62483429, 0.2841361 , 0.43968184,        nan, 0.42686699,
       0.2536456 , 0.33097658,        nan, 0.56076005, 0.40919134,
       0.52850199, 0.67034909, 0.32213875, 0.61820592, 0.43968184,
       0.55368979, 0.5890411 , 0.22403889, 0.53115334, 0.48608042,
       0.40830756, 0.29562528, 0.34909412, 0.16173221, 0.49801149,
       0.56076005, 0.28501989, 0.40300486, 0.65532479, 0.43393725,
       0.47680071, 0.10737958, 0.15863897, 0.49182501,        nan,
       0.40477243,        nan, 0.28767123,        nan, 0.51878038,
       0.22448078, 0.48961555, 0.28501989, 0.44410075, 0.23022536,
       0.65002209, 0.23685373, 0.21873619, 0.57578436, 0.34953601,
       0.1471498 , 0.61157755, 0.56208573, 0.51215201, 0.6394167 ,
       0.46221829, 0.48961555, 0.59611136,        nan, 0.46221829,
       0.62527618, 0.44631021, 0.41449403, 0.25939019, 0.46531153,
       0.12152011, 0.31285904, 0.46663721, 0.44056562, 0.42951834,
       0.36676977,        nan, 0.48166151,        nan, 0.46442775,
       0.55413168, 0.49845338, 0.26955369, 0.55148034, 0.50861688,
              nan, 0.48475475, 0.48873177,        nan,        nan]), 'split4_test_score': array([0.53580902,        nan, 0.32493369, 0.45137047, 0.62687887,
       0.28028294, 0.19319187, 0.54995579,        nan, 0.43589744,
       0.32493369, 0.21352785, 0.66534041, 0.47612732, 0.41114058,
       0.57736516, 0.43457118, 0.45313882, 0.54420866,        nan,
              nan, 0.43766578,        nan,        nan, 0.36516357,
       0.54376658, 0.65738285, 0.60344828, 0.48320071, 0.55349248,
       0.49778957, 0.44650752, 0.29398762, 0.43678161, 0.55835544,
       0.40097259, 0.3974359 , 0.14721485, 0.34173298, 0.38594164,
       0.64014147, 0.49071618, 0.25596817, 0.34571176, 0.43324492,
       0.52917772, 0.14854111, 0.39964633, 0.32183908, 0.17241379,
              nan, 0.4204244 , 0.48938992, 0.35853227, 0.60123784,
              nan, 0.5066313 , 0.10963749, 0.50221043, 0.12466844,
       0.38373121, 0.41688771, 0.57824934, 0.25066313, 0.38682582,
       0.52961981, 0.53050398,        nan, 0.47745358,        nan,
       0.16534041, 0.47480106, 0.57648099, 0.52740937, 0.25198939,
       0.46507515,        nan, 0.27409372,        nan, 0.16445623,
       0.12599469, 0.47877984, 0.31388152, 0.54465075, 0.38019452,
       0.38152078, 0.33996463, 0.50309461, 0.48717949, 0.59725906,
       0.6061008 , 0.32847038, 0.24756852, 0.5495137 , 0.46595933,
       0.51149425, 0.42219275, 0.59504863,        nan, 0.44252874,
              nan, 0.16312997, 0.16091954, 0.44429708, 0.56321839,
              nan, 0.55879752,        nan, 0.28249337, 0.35853227,
       0.66091954, 0.08841733,        nan,        nan, 0.48585323,
       0.62599469, 0.29310345, 0.40937224,        nan, 0.44076039,
       0.29266136, 0.33996463,        nan, 0.56984969, 0.46463307,
       0.51237843, 0.67152962, 0.32404951, 0.61450044, 0.42572944,
       0.55702918, 0.57206012, 0.23253758, 0.51414677, 0.46551724,
       0.41114058, 0.30946065, 0.40141468, 0.22060124, 0.50132626,
       0.55879752, 0.36604775, 0.3311229 , 0.66976127, 0.40450928,
       0.46816976, 0.17948718, 0.2351901 , 0.49204244,        nan,
       0.38992042,        nan, 0.2351901 ,        nan, 0.52033599,
       0.31299735, 0.49602122, 0.29664014, 0.4239611 , 0.19672856,
       0.64544651, 0.24447392, 0.19230769, 0.55702918, 0.3443855 ,
       0.15517241, 0.59416446, 0.53271441, 0.5132626 , 0.62422635,
       0.46507515, 0.49292661, 0.59328028,        nan, 0.4535809 ,
       0.64102564, 0.42351901, 0.4204244 , 0.30901857, 0.47612732,
       0.13218391, 0.3178603 , 0.46595933, 0.4469496 , 0.42882405,
       0.38461538,        nan, 0.46507515,        nan, 0.47038019,
       0.52077807, 0.49911583, 0.27586207, 0.56984969, 0.51016799,
              nan, 0.49734748, 0.48231653,        nan,        nan]), 'mean_test_score': array([0.53844771,        nan, 0.3155391 , 0.44944334, 0.63081104,
       0.27116927, 0.20390572, 0.55232434,        nan, 0.43344551,
       0.30670128, 0.18358052, 0.66466331, 0.47454495, 0.41223254,
       0.57327241, 0.41488595, 0.46208159, 0.54649087,        nan,
              nan, 0.45881022,        nan,        nan, 0.36220638,
       0.53385274, 0.65149425, 0.5957228 , 0.50874796, 0.56098573,
       0.5081306 , 0.44714507, 0.27868263, 0.42381235, 0.55002725,
       0.40542651, 0.39632324, 0.12294717, 0.33586759, 0.38439116,
       0.64177111, 0.48992406, 0.23298771, 0.33118389, 0.43689202,
       0.53102335, 0.15149346, 0.37891292, 0.30864532, 0.1590961 ,
              nan, 0.42531334, 0.488068  , 0.34559068, 0.60146719,
              nan, 0.51263868, 0.09766767, 0.51060559, 0.13036895,
       0.38006043, 0.42469438, 0.5761006 , 0.29387986, 0.39676419,
       0.53517716, 0.5239532 ,        nan, 0.47781506,        nan,
       0.17465005, 0.47339592, 0.58211016, 0.5297859 , 0.26807353,
       0.46782723,        nan, 0.24792524,        nan, 0.14601542,
       0.14839823, 0.48241085, 0.34063755, 0.54596064, 0.40781089,
       0.37413889, 0.32190366, 0.51042891, 0.49284023, 0.55612879,
       0.6117195 , 0.33082885, 0.28459987, 0.55303133, 0.46977163,
       0.50822019, 0.45483183, 0.59881529,        nan, 0.4480285 ,
              nan, 0.22449519, 0.1586532 , 0.44555407, 0.56770333,
              nan, 0.56204673,        nan, 0.32207534, 0.34594419,
       0.66086265, 0.08900472,        nan,        nan, 0.49001201,
       0.61446098, 0.2866366 , 0.42513561,        nan, 0.43309242,
       0.27850576, 0.32490853,        nan, 0.55374015, 0.4193959 ,
       0.51917918, 0.66095197, 0.3209301 , 0.60447322, 0.43043975,
       0.55559497, 0.57477438, 0.24058617, 0.50601097, 0.4774605 ,
       0.41081848, 0.30122046, 0.37440578, 0.17412467, 0.50636335,
       0.56001403, 0.32190597, 0.37599038, 0.6613937 , 0.4380384 ,
       0.46879966, 0.15794781, 0.18234513, 0.48683094,        nan,
       0.38748475,        nan, 0.26365313,        nan, 0.51149097,
       0.2702    , 0.49107344, 0.31023391, 0.42982094, 0.23846193,
       0.64353915, 0.25596504, 0.21371563, 0.566819  , 0.36017184,
       0.15122891, 0.59961062, 0.5503785 , 0.51564412, 0.62002865,
       0.458194  , 0.48957074, 0.5875911 ,        nan, 0.45775109,
       0.63125418, 0.43203036, 0.40807958, 0.28672638, 0.47136333,
       0.11331261, 0.31792469, 0.46314326, 0.45483402, 0.42575597,
       0.37776267,        nan, 0.47136236,        nan, 0.46199473,
       0.55090771, 0.5082191 , 0.26515916, 0.55126556, 0.51555547,
              nan, 0.49646464, 0.48426711,        nan,        nan]), 'std_test_score': array([0.00458619,        nan, 0.00979312, 0.01177087, 0.00740937,
       0.01300797, 0.02044558, 0.01020503,        nan, 0.00587395,
       0.01036841, 0.02272035, 0.00812332, 0.00251551, 0.01656312,
       0.007616  , 0.03197252, 0.00964639, 0.00390939,        nan,
              nan, 0.02259682,        nan,        nan, 0.00489675,
       0.00830982, 0.00754063, 0.00711104, 0.01851808, 0.00567339,
       0.01298184, 0.01426885, 0.01228664, 0.00850795, 0.01106317,
       0.00599732, 0.00639347, 0.02138585, 0.03503336, 0.00197015,
       0.01095632, 0.00956114, 0.01831518, 0.04865455, 0.00650015,
       0.00551411, 0.02955642, 0.05764288, 0.01162491, 0.02139627,
              nan, 0.00330537, 0.00786501, 0.00921192, 0.00758481,
              nan, 0.00972968, 0.00985315, 0.00578157, 0.01362111,
       0.00276849, 0.0094054 , 0.00941665, 0.04146764, 0.02075975,
       0.00491456, 0.01026996,        nan, 0.01181402,        nan,
       0.01867252, 0.00957108, 0.00671863, 0.00698944, 0.01226327,
       0.00910175,        nan, 0.01452257,        nan, 0.01135395,
       0.02072843, 0.01075013, 0.04503681, 0.00955085, 0.04079935,
       0.00580824, 0.01460101, 0.01068445, 0.00752547, 0.03288105,
       0.00915706, 0.04742447, 0.03099826, 0.00318781, 0.01414575,
       0.01136506, 0.02083768, 0.00650518,        nan, 0.0132915 ,
              nan, 0.04791319, 0.02502652, 0.00996779, 0.01019135,
              nan, 0.00576268,        nan, 0.06244915, 0.00916139,
       0.01201915, 0.00166469,        nan,        nan, 0.01129629,
       0.00948897, 0.00538205, 0.02732351,        nan, 0.00461408,
       0.01712747, 0.01032906,        nan, 0.01261565, 0.02516295,
       0.009508  , 0.01531393, 0.00612714, 0.01282305, 0.01267663,
       0.00340094, 0.00988476, 0.01048817, 0.01466749, 0.00917574,
       0.0076784 , 0.0055357 , 0.0380949 , 0.02347966, 0.00841955,
       0.00601191, 0.03013571, 0.02545499, 0.01021181, 0.02247423,
       0.00821321, 0.04144868, 0.03727499, 0.011679  ,        nan,
       0.01074982,        nan, 0.02922025,        nan, 0.0165362 ,
       0.03204352, 0.00875282, 0.03409596, 0.00866335, 0.03913272,
       0.00436574, 0.01313546, 0.0204997 , 0.00651927, 0.02098802,
       0.02617515, 0.00699773, 0.02422143, 0.004511  , 0.01187948,
       0.00481281, 0.00453275, 0.00810047,        nan, 0.00496838,
       0.00672262, 0.0101245 , 0.01387644, 0.01924527, 0.0127266 ,
       0.01178198, 0.01000086, 0.00556069, 0.01682984, 0.01247513,
       0.00695501,        nan, 0.00995147,        nan, 0.01055163,
       0.01918029, 0.01088388, 0.01023682, 0.0130502 , 0.00743784,
              nan, 0.00748609, 0.00816329,        nan,        nan]), 'rank_test_score': array([ 39, 176, 132,  85,   9, 143, 155,  32, 173,  91, 135, 156,   1,
        70, 103,  22, 102,  78,  37, 184, 196,  80, 195, 193, 118,  41,
         5,  17,  52,  26,  55,  87, 141, 100,  36, 107, 109, 168, 123,
       111,   7,  62, 152, 124,  90,  42, 163, 113, 134, 160, 181,  97,
        64, 121,  14, 186,  48, 170,  50, 167, 112,  99,  20, 137, 108,
        40,  44, 185,  68, 191, 158,  71,  19,  43, 145,  76, 198, 149,
       180, 166, 165,  67, 122,  38, 106, 117, 129,  51,  59,  28,  12,
       125, 140,  31,  74,  53,  84,  16, 192,  86, 188, 153, 161,  88,
        23, 183,  25, 199, 127, 120,   4, 171, 174, 179,  61,  11, 139,
        98, 175,  92, 142, 126, 172,  30, 101,  45,   3, 130,  13,  94,
        29,  21, 150,  57,  69, 104, 136, 116, 159,  56,  27, 128, 115,
         2,  89,  75, 162, 157,  65, 197, 110, 190, 147, 187,  49, 144,
        60, 133,  95, 151,   6, 148, 154,  24, 119, 164,  15,  35,  46,
        10,  81,  63,  18, 194,  82,   8,  93, 105, 138,  72, 169, 131,
        77,  83,  96, 114, 177,  73, 182,  79,  34,  54, 146,  33,  47,
       178,  58,  66, 189, 200], dtype=int32)}